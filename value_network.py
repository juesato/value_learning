import numpy as np
import tensorflow as tf
from encoder import GRU

def train_epoch(sess, trainable_model, data_loader):
    losses = []
    data_loader.reset()
    for it in xrange(data_loader.num_batch):
        batch = data_loader.next_batch()
        _, loss = trainable_model.train(sess, batch)
        losses.append(loss)

    return np.mean(losses)

class ValueNetwork:
    def __init__():

    def build():
        self.x1 = tf.placeholder(tf.int32, shape=[self.batch_size, self.sequence_length]) # sequence of tokens generated by generator
        self.x2 = tf.placeholder(tf.int32, shape=[self.batch_size, self.sequence_length]) # sequence of tokens generated by generator

        self.h0 = tf.Variable(self.init_matrix([self.batch_size, 2]))

        with tf.device("/cpu:0"):
            self.processed_x1 = tf.transpose(tf.nn.embedding_lookup(self.g_embeddings, self.x1), perm=[1, 0, 2])  # seq_length x batch_size x emb_dim
            self.processed_x2 = tf.transpose(tf.nn.embedding_lookup(self.g_embeddings, self.x2), perm=[1, 0, 2])  # seq_length x batch_size x emb_dim

        args = None
        self.enc1 = GRU(args)
        self.enc1_outs = self.enc1.build(self.h0, self.processed_x1)
        self.enc2 = GRU(args)
        self.enc2_outs = self.enc2.build(self.enc1_outs[-1], self.processed_x2)
        self.scores = self.enc2_outs * vector

        self.optimizer = tf.train.AdamOptimizer()
        self.loss = tf.losses.mean_squared_error(self.ys, self.scores)
        self.clipped_grads = tf.clip_by_global_norm(tf.gradients(self.loss, tf.trainable_variables()), self.grad_clip)
        self.update = self.optimizer.apply_gradients(self.grads, self.params)

    def train(self, sess, x, y):
        outputs = sess.run(self.updates, self.loss, feed_dict={
                self.x1: x[0]
                self.x2: x[1]
                self.y: y
            })
        return outputs

def main():
    random.seed(SEED)
    np.random.seed(SEED)

    # config = tf.ConfigProto()
    sess = tf.Session()
    # sess.run(tf.global_variables_initializer())
    value_learner = ValueNetwork()
    value_learner.build()


    print "starting"

    for epoch in xrange(NUM_EPOCHS):
        train_epoch(sess, value_learner, data_loader)
